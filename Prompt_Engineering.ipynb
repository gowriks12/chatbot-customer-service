{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMqalRjnk8LkF3m+/Ei4f38",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gowriks12/chatbot-customer-service/blob/main/Prompt_Engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Customer Service Chatbot**"
      ],
      "metadata": {
        "id": "ljFDh1mbcAm1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Large Language Model**"
      ],
      "metadata": {
        "id": "R28nmS88fDAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceCuLQksfCLj",
        "outputId": "550d218e-20df-447b-d32f-237e23e8e202"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Feb 21 22:31:38 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers datasets accelerate peft"
      ],
      "metadata": {
        "id": "vsC82-rpAiem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "M1iGPX8UCZWk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_id=\"google/flan-t5-large\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_id)"
      ],
      "metadata": {
        "id": "LP3EM2wnCeM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_dataset(\"bitext/Bitext-customer-support-llm-chatbot-training-dataset\")\n",
        "df = data[\"train\"].to_pandas()\n",
        "df = df[[\"instruction\", \"response\"]]"
      ],
      "metadata": {
        "id": "f_NAOzAZx_uZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_indices = [401, 3000]\n",
        "\n",
        "dash_line = '-'.join('' for x in range(100))\n",
        "\n",
        "for i, index in enumerate(example_indices):\n",
        "    print(dash_line)\n",
        "    print('Example ', i + 1)\n",
        "    print(dash_line)\n",
        "    print('INPUT Query:')\n",
        "    print(df['instruction'][index])\n",
        "    print(dash_line)\n",
        "    print('BASELINE HUMAN Response:')\n",
        "    print(df['response'][index])\n",
        "    print(dash_line)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FckOWrdlyuHU",
        "outputId": "52810a7a-bd29-4370-d87f-14d090369415"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------------------------\n",
            "Example  1\n",
            "---------------------------------------------------------------------------------------------------\n",
            "INPUT Query:\n",
            "cance order {{Order Number}}\n",
            "---------------------------------------------------------------------------------------------------\n",
            "BASELINE HUMAN Response:\n",
            "I've decoded that you need assistance with canceling the order with order number {{Order Number}}. We apologize for any inconvenience this may have caused you. To proceed with the cancellation, please follow these steps:\n",
            "\n",
            "1. Sign into Your Account: Access our platform by signing in to your {{Online Company Portal Info}}.\n",
            "2. Go to Order History: Once signed in, navigate to the '{{Online Order Interaction}}' or '{{Online Order Interaction}}' section.\n",
            "3. Locate Your Order: Look for the order with the order number {{Order Number}} and click on it to view the details.\n",
            "4. Cancel Your Order: Within the order details page, you should find an option labeled '{{Online Order Interaction}}'. Please select this option to initiate the cancellation process.\n",
            "5. Confirmation and Feedback: You might be prompted to provide feedback or confirm the cancellation. Please follow the instructions provided by the system.\n",
            "\n",
            "If you encounter any difficulties or have any further questions, please don't hesitate to reach out to our dedicated support team. You can contact us during {{Customer Support Hours}} at {{Customer Support Phone Number}} or chat with us live on our {{Website URL}}. We are here to assist you and ensure your satisfaction.\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Example  2\n",
            "---------------------------------------------------------------------------------------------------\n",
            "INPUT Query:\n",
            "want help to see the termination charge\n",
            "---------------------------------------------------------------------------------------------------\n",
            "BASELINE HUMAN Response:\n",
            "I'll make it happen! I can provide you with assistance in viewing the termination charge. To do so, you can log in to your account and navigate to the section where your account details are displayed. Look for any information related to termination or cancellation fees, and you should find the details you're looking for. If you're unable to locate this information, please let me know and I'll be more than happy to help you further.\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, index in enumerate(example_indices):\n",
        "    instruction = df['instruction'][index]\n",
        "    response = df['response'][index]\n",
        "\n",
        "    inputs = tokenizer(instruction, return_tensors='pt')\n",
        "    output = tokenizer.decode(\n",
        "        model.generate(\n",
        "            inputs[\"input_ids\"],\n",
        "            max_new_tokens=50,\n",
        "        )[0],\n",
        "        skip_special_tokens=True\n",
        "    )\n",
        "\n",
        "    print(dash_line)\n",
        "    print('Example ', i + 1)\n",
        "    print(dash_line)\n",
        "    print(f'INPUT PROMPT:\\n{instruction}')\n",
        "    print(dash_line)\n",
        "    print(f'BASELINE HUMAN SUMMARY:\\n{response}')\n",
        "    print(dash_line)\n",
        "    print(f'MODEL GENERATION - WITHOUT PROMPT ENGINEERING:\\n{output}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPmNvpUz1eK7",
        "outputId": "bbea5220-a2ed-4ad7-e265-6d0e3a2f6cd2"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------------------------\n",
            "Example  1\n",
            "---------------------------------------------------------------------------------------------------\n",
            "INPUT PROMPT:\n",
            "cance order {{Order Number}}\n",
            "---------------------------------------------------------------------------------------------------\n",
            "BASELINE HUMAN SUMMARY:\n",
            "I've decoded that you need assistance with canceling the order with order number {{Order Number}}. We apologize for any inconvenience this may have caused you. To proceed with the cancellation, please follow these steps:\n",
            "\n",
            "1. Sign into Your Account: Access our platform by signing in to your {{Online Company Portal Info}}.\n",
            "2. Go to Order History: Once signed in, navigate to the '{{Online Order Interaction}}' or '{{Online Order Interaction}}' section.\n",
            "3. Locate Your Order: Look for the order with the order number {{Order Number}} and click on it to view the details.\n",
            "4. Cancel Your Order: Within the order details page, you should find an option labeled '{{Online Order Interaction}}'. Please select this option to initiate the cancellation process.\n",
            "5. Confirmation and Feedback: You might be prompted to provide feedback or confirm the cancellation. Please follow the instructions provided by the system.\n",
            "\n",
            "If you encounter any difficulties or have any further questions, please don't hesitate to reach out to our dedicated support team. You can contact us during {{Customer Support Hours}} at {{Customer Support Phone Number}} or chat with us live on our {{Website URL}}. We are here to assist you and ensure your satisfaction.\n",
            "---------------------------------------------------------------------------------------------------\n",
            "MODEL GENERATION - WITHOUT PROMPT ENGINEERING:\n",
            "cance order Order Number\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Example  2\n",
            "---------------------------------------------------------------------------------------------------\n",
            "INPUT PROMPT:\n",
            "want help to see the termination charge\n",
            "---------------------------------------------------------------------------------------------------\n",
            "BASELINE HUMAN SUMMARY:\n",
            "I'll make it happen! I can provide you with assistance in viewing the termination charge. To do so, you can log in to your account and navigate to the section where your account details are displayed. Look for any information related to termination or cancellation fees, and you should find the details you're looking for. If you're unable to locate this information, please let me know and I'll be more than happy to help you further.\n",
            "---------------------------------------------------------------------------------------------------\n",
            "MODEL GENERATION - WITHOUT PROMPT ENGINEERING:\n",
            "i want help to see the termination charge\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Zero Shot Prompting**"
      ],
      "metadata": {
        "id": "uuF4gb_XcGxW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "rsNLvdrnbCHN"
      },
      "outputs": [],
      "source": [
        "def zero_shot(query):\n",
        "  prompt = f\"\"\"\n",
        "  Reply to the query as a customer service agent\n",
        "\n",
        "  {query}\n",
        "\n",
        "  Reply:\n",
        "  \"\"\"\n",
        "  inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "  outputs = model.generate(**inputs, max_new_tokens=20)\n",
        "  return tokenizer.batch_decode(outputs, skip_special_tokens=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, index in enumerate(example_indices):\n",
        "  query = df['instruction'][index]\n",
        "  response = df['response'][index]\n",
        "  output = zero_shot(query)\n",
        "\n",
        "  print(dash_line)\n",
        "  print('Example ', i + 1)\n",
        "  print(dash_line)\n",
        "  print(f'INPUT PROMPT:\\n{query}')\n",
        "  print(dash_line)\n",
        "  print(f'BASELINE HUMAN SUMMARY:\\n{response}')\n",
        "  print(dash_line)\n",
        "  print(f'MODEL GENERATION - WITH ZERO SHOT PROMPT ENGINEERING:\\n{output}\\n')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5gYk_n-2jJw",
        "outputId": "2765337f-5f71-45a7-8856-3aa699c234fe"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Example  1\n",
            "---------------------------------------------------------------------------------------------------\n",
            "INPUT PROMPT:\n",
            "cance order {{Order Number}}\n",
            "---------------------------------------------------------------------------------------------------\n",
            "BASELINE HUMAN SUMMARY:\n",
            "I've decoded that you need assistance with canceling the order with order number {{Order Number}}. We apologize for any inconvenience this may have caused you. To proceed with the cancellation, please follow these steps:\n",
            "\n",
            "1. Sign into Your Account: Access our platform by signing in to your {{Online Company Portal Info}}.\n",
            "2. Go to Order History: Once signed in, navigate to the '{{Online Order Interaction}}' or '{{Online Order Interaction}}' section.\n",
            "3. Locate Your Order: Look for the order with the order number {{Order Number}} and click on it to view the details.\n",
            "4. Cancel Your Order: Within the order details page, you should find an option labeled '{{Online Order Interaction}}'. Please select this option to initiate the cancellation process.\n",
            "5. Confirmation and Feedback: You might be prompted to provide feedback or confirm the cancellation. Please follow the instructions provided by the system.\n",
            "\n",
            "If you encounter any difficulties or have any further questions, please don't hesitate to reach out to our dedicated support team. You can contact us during {{Customer Support Hours}} at {{Customer Support Phone Number}} or chat with us live on our {{Website URL}}. We are here to assist you and ensure your satisfaction.\n",
            "---------------------------------------------------------------------------------------------------\n",
            "MODEL GENERATION - WITH ZERO SHOT PROMPT ENGINEERING:\n",
            "['I can help you with that.']\n",
            "\n",
            "1\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Example  2\n",
            "---------------------------------------------------------------------------------------------------\n",
            "INPUT PROMPT:\n",
            "want help to see the termination charge\n",
            "---------------------------------------------------------------------------------------------------\n",
            "BASELINE HUMAN SUMMARY:\n",
            "I'll make it happen! I can provide you with assistance in viewing the termination charge. To do so, you can log in to your account and navigate to the section where your account details are displayed. Look for any information related to termination or cancellation fees, and you should find the details you're looking for. If you're unable to locate this information, please let me know and I'll be more than happy to help you further.\n",
            "---------------------------------------------------------------------------------------------------\n",
            "MODEL GENERATION - WITH ZERO SHOT PROMPT ENGINEERING:\n",
            "['I am sorry, we are not able to help you with this request.']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**One Shot Prompting**"
      ],
      "metadata": {
        "id": "hFEsLl4ueUG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def one_shot(query, prompt_indices):\n",
        "  prompt = ''\n",
        "  # print(prompt_indices)\n",
        "  for index in prompt_indices:\n",
        "    ex_query = df['instruction'][index]\n",
        "    ex_response = df['response'][index]\n",
        "\n",
        "    prompt += f\"\"\"\n",
        "    Reply to the query as a customer service agent\n",
        "\n",
        "    Query:\n",
        "    {ex_query}\n",
        "\n",
        "    Response:\n",
        "    {ex_response}\n",
        "    \"\"\"\n",
        "\n",
        "  prompt += f\"\"\"\n",
        "  Query:\n",
        "  {query}\n",
        "\n",
        "  Response:\n",
        "  \"\"\"\n",
        "  # print(\"One-Shot Prompt\\n\", prompt)\n",
        "\n",
        "  inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "  outputs = model.generate(**inputs, max_new_tokens=20)\n",
        "  return tokenizer.batch_decode(outputs, skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "cCNYQ2tsefV5"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, index in enumerate(example_indices):\n",
        "    query = df['instruction'][index]\n",
        "    response = df['response'][index]\n",
        "    prompt_indices = [560]\n",
        "    output = one_shot(query, prompt_indices)\n",
        "\n",
        "    print(dash_line)\n",
        "    print('Example ', i + 1)\n",
        "    print(dash_line)\n",
        "    print(f'INPUT PROMPT:\\n{query}')\n",
        "    print(dash_line)\n",
        "    print(f'BASELINE HUMAN SUMMARY:\\n{response}')\n",
        "    print(dash_line)\n",
        "    print(f'MODEL GENERATION - WITH ONE SHOT PROMPT ENGINEERING:\\n{output}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbVFfu0l3pFp",
        "outputId": "0426b964-108f-482c-db8a-5ac30275872f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------------------------\n",
            "Example  1\n",
            "---------------------------------------------------------------------------------------------------\n",
            "INPUT PROMPT:\n",
            "cance order {{Order Number}}\n",
            "---------------------------------------------------------------------------------------------------\n",
            "BASELINE HUMAN SUMMARY:\n",
            "I've decoded that you need assistance with canceling the order with order number {{Order Number}}. We apologize for any inconvenience this may have caused you. To proceed with the cancellation, please follow these steps:\n",
            "\n",
            "1. Sign into Your Account: Access our platform by signing in to your {{Online Company Portal Info}}.\n",
            "2. Go to Order History: Once signed in, navigate to the '{{Online Order Interaction}}' or '{{Online Order Interaction}}' section.\n",
            "3. Locate Your Order: Look for the order with the order number {{Order Number}} and click on it to view the details.\n",
            "4. Cancel Your Order: Within the order details page, you should find an option labeled '{{Online Order Interaction}}'. Please select this option to initiate the cancellation process.\n",
            "5. Confirmation and Feedback: You might be prompted to provide feedback or confirm the cancellation. Please follow the instructions provided by the system.\n",
            "\n",
            "If you encounter any difficulties or have any further questions, please don't hesitate to reach out to our dedicated support team. You can contact us during {{Customer Support Hours}} at {{Customer Support Phone Number}} or chat with us live on our {{Website URL}}. We are here to assist you and ensure your satisfaction.\n",
            "---------------------------------------------------------------------------------------------------\n",
            "MODEL GENERATION - WITH ONE SHOT PROMPT ENGINEERING:\n",
            "[\"I see your situation, and I'm here to assist you with canceling order Or\"]\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Example  2\n",
            "---------------------------------------------------------------------------------------------------\n",
            "INPUT PROMPT:\n",
            "want help to see the termination charge\n",
            "---------------------------------------------------------------------------------------------------\n",
            "BASELINE HUMAN SUMMARY:\n",
            "I'll make it happen! I can provide you with assistance in viewing the termination charge. To do so, you can log in to your account and navigate to the section where your account details are displayed. Look for any information related to termination or cancellation fees, and you should find the details you're looking for. If you're unable to locate this information, please let me know and I'll be more than happy to help you further.\n",
            "---------------------------------------------------------------------------------------------------\n",
            "MODEL GENERATION - WITH ONE SHOT PROMPT ENGINEERING:\n",
            "[\"I see your issue, and I'm here to help you. To see the termination charge,\"]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Few Shot Prompting**"
      ],
      "metadata": {
        "id": "deOtHwcrefv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def few_shot(query, prompt_indices):\n",
        "  prompt = ''\n",
        "  for index in prompt_indices:\n",
        "    ex_query = df['instruction'][index]\n",
        "    ex_response = df['response'][index]\n",
        "\n",
        "    prompt += f\"\"\"\n",
        "    Reply to the query as a customer service agent\n",
        "\n",
        "    Query:\n",
        "    {ex_query}\n",
        "\n",
        "    Response:\n",
        "    {ex_response}\n",
        "    \"\"\"\n",
        "\n",
        "  prompt += f\"\"\"\n",
        "  Query:\n",
        "  {query}\n",
        "\n",
        "  Response:\n",
        "  \"\"\"\n",
        "  # print(\"Few-Shot Prompt\\n\", prompt)\n",
        "\n",
        "  inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "  outputs = model.generate(**inputs, max_new_tokens=20)\n",
        "  return tokenizer.batch_decode(outputs, skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "bgDa8YgVemvT"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, index in enumerate(example_indices):\n",
        "    query = df['instruction'][index]\n",
        "    response = df['response'][index]\n",
        "    prompt_indices = [560, 2, 8]\n",
        "    output = few_shot(query, prompt_indices)\n",
        "\n",
        "    print(dash_line)\n",
        "    print('Example ', i + 1)\n",
        "    print(dash_line)\n",
        "    print(f'INPUT PROMPT:\\n{query}')\n",
        "    print(dash_line)\n",
        "    print(f'BASELINE HUMAN SUMMARY:\\n{response}')\n",
        "    print(dash_line)\n",
        "    print(f'MODEL GENERATION - WITH FEW SHOT PROMPT ENGINEERING:\\n{output}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJlWxbt278Cl",
        "outputId": "728b4386-379b-4636-85de-ebce0d55d0df"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------------------------\n",
            "Example  1\n",
            "---------------------------------------------------------------------------------------------------\n",
            "INPUT PROMPT:\n",
            "cance order {{Order Number}}\n",
            "---------------------------------------------------------------------------------------------------\n",
            "BASELINE HUMAN SUMMARY:\n",
            "I've decoded that you need assistance with canceling the order with order number {{Order Number}}. We apologize for any inconvenience this may have caused you. To proceed with the cancellation, please follow these steps:\n",
            "\n",
            "1. Sign into Your Account: Access our platform by signing in to your {{Online Company Portal Info}}.\n",
            "2. Go to Order History: Once signed in, navigate to the '{{Online Order Interaction}}' or '{{Online Order Interaction}}' section.\n",
            "3. Locate Your Order: Look for the order with the order number {{Order Number}} and click on it to view the details.\n",
            "4. Cancel Your Order: Within the order details page, you should find an option labeled '{{Online Order Interaction}}'. Please select this option to initiate the cancellation process.\n",
            "5. Confirmation and Feedback: You might be prompted to provide feedback or confirm the cancellation. Please follow the instructions provided by the system.\n",
            "\n",
            "If you encounter any difficulties or have any further questions, please don't hesitate to reach out to our dedicated support team. You can contact us during {{Customer Support Hours}} at {{Customer Support Phone Number}} or chat with us live on our {{Website URL}}. We are here to assist you and ensure your satisfaction.\n",
            "---------------------------------------------------------------------------------------------------\n",
            "MODEL GENERATION - WITH FEW SHOT PROMPT ENGINEERING:\n",
            "[\"I can sense that you're seeking assistance with canceling order Order Number.\"]\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Example  2\n",
            "---------------------------------------------------------------------------------------------------\n",
            "INPUT PROMPT:\n",
            "want help to see the termination charge\n",
            "---------------------------------------------------------------------------------------------------\n",
            "BASELINE HUMAN SUMMARY:\n",
            "I'll make it happen! I can provide you with assistance in viewing the termination charge. To do so, you can log in to your account and navigate to the section where your account details are displayed. Look for any information related to termination or cancellation fees, and you should find the details you're looking for. If you're unable to locate this information, please let me know and I'll be more than happy to help you further.\n",
            "---------------------------------------------------------------------------------------------------\n",
            "MODEL GENERATION - WITH FEW SHOT PROMPT ENGINEERING:\n",
            "['I can help you with this. Is there a way to see the termination charge?']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fine-Tuned Chatbot**"
      ],
      "metadata": {
        "id": "BeSdo8U-fRQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from peft import PeftModel, PeftConfig\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "\n",
        "# Load peft config for pre-trained checkpoint etc.\n",
        "peft_model_id = \"/content/drive/MyDrive/Chatbot\"\n",
        "config = PeftConfig.from_pretrained(peft_model_id)\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(config.base_model_name_or_path)\n",
        "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
        "\n",
        "model = PeftModel.from_pretrained(model, peft_model_id, device_map={\"\":0}).cuda()\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "aIUSORJ4fZc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def finetuned_response(query):\n",
        "  # sample = \"instruction: \\nI am looking for a product {product ID}, please find it for me \\nresponse: \"\n",
        "  input_ids = tokenizer(query, return_tensors=\"pt\", truncation=True, max_length=256).input_ids.cuda()\n",
        "  outputs = model.generate(input_ids=input_ids, do_sample=True, top_p=0.9, max_length=256)\n",
        "  # print(f\"{sample}\")\n",
        "\n",
        "  return (tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)[0])"
      ],
      "metadata": {
        "id": "Qf4pO-xKMogI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"I am looking for a product {product ID}, please find it for me\"\n",
        "print(finetuned_response(query))"
      ],
      "metadata": {
        "id": "lMhWG13yMxu-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}